# OGeek算法挑战赛
## 赛题与baseline
赛题与数据：https://tianchi.aliyun.com/competition/information.htm?spm=5176.11165320.5678.2.29a711a3nQFbgF&raceId=231688   
开源baseline: https://zhuanlan.zhihu.com/p/46482521  
开源baseline说明：
* 特征：使用了CTR从原数据中提取特征,如单字段点击率和组合字段点击率。
* 模型：LightGbm
* 验证：5折交叉
* 效果：线上70%
## 改进思路
* 特征：  
  1. 抽取文本相似度特征
     早期：由于prefix较短，且不能完整反映用户输入意图，直接度量和title之间的相似度会产生偏差，我们采取选择query_prediction中概率最大的query为用户输入意图，度量其和title之间的相似度。
     中期：在早期的基础上，逐一比较query_prefiction中的item和title之间的相似度，保存相似度最大值及对应的item。
     后期：对早期和中期获得的相似度取均值，作为prefix和title之间的近似相似度。
  2. 特征分箱
     对连续的相似度特征进行分箱。
* 数据预处理：
  1. 缺失值填补：对于数值缺失值，填0.
  2. 标准化：将连续数值处理为均值为0，方差为1的数据。
* 模型选择：
  由于赛题模型个数限制（2个），很多集成学习方法如Stacking、boosting无法使用。由于经验，多个模型融合效果一般好于单个模型效果，如何设计2个模型的结构是提升效果的重要方面。
## 实验效果
* 特征：CTR+文本相似度
* 模型：LightGbm
* 效果：线下接近80%，线上约73%
## 缺点
* 由于时间匆促，对于文本相似度的度量采用了现有的第三方库[synonyms](https://github.com/huyingxi/Synonyms)。若是能根据数据特点自主进行分词、并建立自定义词典，自主使用word2vec训练词向量或者sen2vec，计算相似度可能效果更好一点。
* 对于数据的缺失值，使用全0填补比较粗糙，若是尝试多种填补方式对结果也能起到提升。
* 未来得及对其他模型进行验证。
* 文本分类的思路未来得及验证。
## 总结
和同学第一次参加天池比赛，对于实践中如何分析数据、如何获取特征、如何应用模型、如何找到自己需要的资料有了初步的认识，对于自身在编码能力方面的不足、对于理论知识的缺乏也有了深刻反思。总之收获多多。
OGeek比赛即将落幕，到时学习下大佬的思路和代码，以弥补自身不足。
